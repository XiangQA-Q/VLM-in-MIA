# VLM-in-MIA

## VLM in Medical image diagnosis and classification
|Paper|PDF|Code|
|---|---|---|
|ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.html)|-|
|BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_69)|[Code](https://github.com/monajati/BERTHop)|
|TandemNet: Distilling Knowledge from Medical Images Using Diagnostic Reports as Optional Semantic References|[PDF](https://link.springer.com/chapter/10.1007/978-3-319-66179-7_37)|-|
|Pay attention to doctor–patient dialogues: Multi-modal knowledge graph attention image-text embedding for COVID-19 diagnosis|[PDF](https://www.sciencedirect.com/science/article/pii/S1566253521001159)|-|
|Text-Guided Foundation Model Adaptation for Pathological Image Classification|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_27)|[Code](https://github.com/Yunkun-Zhang/CITE)|
|Report-Concept Textual-Prompt Learning for Enhancing X-ray Diagnosis|[PDF](https://dl.acm.org/doi/abs/10.1145/3664647.3681568)|-|
|A diagnostic report supervised deep learning model training strategy for diagnosis of COVID-19|[PDF](https://www.sciencedirect.com/science/article/pii/S0031320323009299)|-|
|Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-47401-9_22)|-|
|Nodule-CLIP: Lung nodule classification based on multi-modal contrastive learning|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S0010482524005894)|-|
|Contrastive Cross-Modal Pre-Training: A General Strategy for Small Sample Medical Imaging|[PDF](https://ieeexplore.ieee.org/abstract/document/9531406/)|-|
|FlexR: Few-shot Classification with Language Embeddings for Structured Reporting of Chest X-rays|[PDF](https://proceedings.mlr.press/v227/keicher24a.html)|-|
|The Rise of AI Language Pathologists: Exploring Two-level Prompt Learning for Few-shot Weakly-supervised Whole Slide Image Classification|[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d599b81036fd1a3b3949b7d444f31082-Abstract-Conference.html)|[Code](https://github.com/miccaiif/TOP)|
|Exploring low-resource medical image classification with weakly supervised prompt learning|[PDF](https://www.sciencedirect.com/science/article/pii/S0031320324000013)|-|
|Self-supervised multi-modal training from uncurated images and reports enables monitoring AI in radiology|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S1361841523002815)]|-|
|CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Lai_CARZero_Cross-Attention_Alignment_for_Radiology_Zero-Shot_Classification_CVPR_2024_paper.html)|[Code](https://github.com/laihaoran/CARZero)|
|Multi-Label Generalized Zero Shot Chest Xray Classification By Combining Image-Text Information With Feature Disentanglement|[PDF](https://ieeexplore.ieee.org/abstract/document/10601163/)|-|
|TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-rays|[PDF](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_TieNet_Text-Image_Embedding_CVPR_2018_paper.html)|-|
|Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Pre-training Framework|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Phan_Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_CVPR_2024_paper.html)|[Code](https://github.com/HieuPhan33/MAVL)|
|Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images|[PDF](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Visual_Language_Pretrained_Multiple_Instance_Zero-Shot_Transfer_for_Histopathology_Images_CVPR_2023_paper.html)|[Code](https://github.com/mahmoodlab/MI-Zero)|
|CLIPath: Fine-tune CLIP with Visual Feature Fusion for Pathology Image Analysis Towards Minimizing Data Collection Efforts|[PDF](https://openaccess.thecvf.com/content/ICCV2023W/CVAMD/html/Lai_CLIPath_Fine-Tune_CLIP_with_Visual_Feature_Fusion_for_Pathology_Image_ICCVW_2023_paper.html)|-|


## KD in Medical image segmentation

|Paper|PDF|Code|
|---|---|---|
|Ariadne’s Thread: Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray Images|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43901-8_69)|[Code](https://github.com/Junelin2333/LanGuideMedSeg-MICCAI2023)|
|Text-guided cross-position attention for segmentation: Case of medical image|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_52)|-|
|ConTEXTual net: a multimodal vision-language model for segmentation of pneumothorax|[PDF](https://link.springer.com/article/10.1007/s10278-024-01051-8)|[Code](https://github.com/zhuemann/ConTEXTualSegmentation)|
|TPRO: Text-Prompting-Based weakly supervised histopathology tissue segmentation|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43907-0_11)|[Code](https://github.com/zhangst431/TPRO)|
|Text promptable surgical instrument segmentation with vision-language models|[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/hash/5af741d487c5f0b08bfe56e11d1883e4-Abstract-Conference.html)|[Code](https://github.com/franciszzj/TP-SIS)|
|Bi-VLGM: Bi-Level Class-Severity-Aware Vision-Language Graph Matching for Text Guided Medical Image Segmentation|[PDF](https://arxiv.org/abs/2305.12231)|-|
|Cross-Modal Conditioned Reconstruction for Language-guided Medical Image Segmentation|[PDF](https://arxiv.org/abs/2404.02845)|[Code](https://github.com/ShashankHuang/RecLMIS)|
|VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72114-4_68)|[Code](https://github.com/naamiinepal/vlsm-adapter)|
|CAT: Coordinating Anatomical-Textual Prompts for Multi-Organ and Tumor Segmentation|[PDF](https://arxiv.org/abs/2406.07085)|[Code](https://github.com/zongzi3zz/CAT)|
|Universal and extensible language-vision models for organ segmentation and tumor detection from abdominal computed tomography|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S1361841524001518)|[Code](https://github.com/ljwztc/CLIP-Driven-Universal-Model)|
|Clip-driven universal model for organ segmentation and tumor detection|[PDF](http://openaccess.thecvf.com/content/ICCV2023/html/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.html)|[Code](https://github.com/ljwztc/CLIP-Driven-Universal-Model)|
|FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation|[PDF](https://arxiv.org/abs/2403.08059)|[Code](https://github.com/arcadelab/fluorosam)|
|Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation|[PDF](https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Aleem_Test-Time_Adaptation_with_SaLIP_A_Cascade_of_SAM_and_CLIP_CVPRW_2024_paper.html)|[Code](https://github.com/aleemsidra/SaLIP)|
|Zept: Zero-shot pan-tumor segmentation via query-disentangling and self-prompting|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_ZePT_Zero-Shot_Pan-Tumor_Segmentation_via_Query-Disentangling_and_Self-Prompting_CVPR_2024_paper.html)|[Code](https://github.com/Yankai96/ZePT)|
|PFPs: Prompt-guided Flexible Pathological Segmentation for Diverse Potential Outcomes Using Large Vision and Language Models|[PDF](https://arxiv.org/abs/2407.09979)|-|
|MedCLIP-SAM: Bridging text and image towards universal medical image segmentation|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72390-2_60)|[Code](https://github.com/HealthX-Lab/MedCLIP-SAM)|
|Lvit: language meets vision transformer in medical image segmentation|[PDF](https://ieeexplore.ieee.org/abstract/document/10172039/)|[Code](https://github.com/HUANGLIZI/LViT)|
|Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports|[PDF](https://arxiv.org/abs/2405.14230)|-|
|SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging|[PDF](https://arxiv.org/abs/2403.16578)|-|
|Generative text-guided 3d vision-language pretraining for unified medical image segmentation|[PDF](https://arxiv.org/abs/2306.04811)|-|
|T3d: Towards 3d medical image understanding through vision-language pre-training|[PDF](https://arxiv.org/abs/2312.01529)|-|
|One model to rule them all: Towards universal segmentation for medical images with text prompts|[PDF](https://arxiv.org/abs/2312.17183)|[Code](https://github.com/zhaoziheng/SAT)|
|Med3DInsight: Enhancing 3D Medical Image Understanding with 2D Multi-Modal Large Language Models|[PDF](https://arxiv.org/abs/2403.05141)|[Code](https://github.com/Qybc/Med3DInsight)|


## KD in Medical image report generation

|Paper|PDF|Code|
|---|---|---|
|AERMNet: Attention-enhanced relational memory network for medical image report generation|[PDF]()|[Code]()|
|Kdtnet: medical image report generation via knowledge-driven transformer|[PDF]()|[Code]()|
|RepsNet: Combining Vision with Language for Automated Medical Reports|[PDF]()|[Code]()|
|Radiology Report Generation via Visual Recalibration and Context Gating-Aware|[PDF]()|[Code]()|
|Visual-Textual Attentive Semantic Consistency for Medical Report Generation|[PDF]()|[Code]()|
|CGFTrans: Cross-Modal Global Feature Fusion Transformer for Medical Report Generation|[PDF]()|[Code]()|
|CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs|[PDF]()|[Code]()|
|Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting|[PDF]()|[Code]()|
|PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation|[PDF]()|[Code]()|
|A label information fused medical image report generation framework|[PDF]()|[Code]()|
|Clinical-BERT: Vision-Language Pre-training for Radiograph Diagnosis and Reports Generation|[PDF]()|[Code]()|
|Dia-LLaMA: Towards Large Language Model-driven CT Report Generation|[PDF]()|[Code]()|
|TRRG: Towards Truthful Radiology Report Generation With Cross-modal Disease Clue Enhanced Large Language Model|[PDF]()|[Code]()|
|An Organ-aware Diagnosis Framework for Radiology Report Generation|[PDF]()|[Code]()|
|MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation|[PDF]()|[Code]()|
|Non-local Attention Improves Description Generation for Retinal Images|[PDF]()|[Code]()|
|Enhancing the vision–language foundation model with key semantic knowledge-emphasized report refinement|[PDF]()|[Code]()|
|Vision-language model for generating textual descriptions from clinical images: model development and validation study|[PDF]()|[Code]()|
|IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training|[PDF]()|[Code]()|
|METransformer: Radiology Report Generation by Transformer with Multiple Learnable Expert Tokens|[PDF]()|[Code]()|
|Prior Guided Transformer for Accurate Radiology Reports Generation|[PDF]()|[Code]()|
|Multimodal image-text matching improves retrieval-based chest x-ray report generation|[PDF]()|[Code]()|
|PhraseAug: An Augmented Medical Report Generation Model with Phrasebook|[PDF]()|[Code]()|
|Fine-grained image-text alignment in medical imaging enables cyclic image-report generation|[PDF]()|[Code]()|
|FgKF: Fine-Grained Knowledge Fusion for Radiology Report Generation|[PDF]()|[Code]()|
|Multi-Grained Radiology Report Generation With Sentence-Level Image-Language Contrastive Learning|[PDF]()|[Code]()|
|AlignTransformer: Hierarchical Alignment of Visual Regions and Disease Tags for Medical Report Generation|[PDF]()|[Code]()|
|Improving radiology report generation with multi-grained abnormality prediction|[PDF]()|[Code]()|
|Self adaptive global-local feature enhancement for radiology report generation|[PDF]()|[Code]()|
|Interactive and Explainable Region-guided Radiology Report Generation|[PDF]()|[Code]()|
|Complex Organ Mask Guided Radiology Report Generation|[PDF]()|[Code]()|
|Attribute Prototype-guided Iterative Scene Graph for Explainable Radiology Report Generation|[PDF]()|[Code]()|
|Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation|[PDF]()|[Code]()|


## KD in Medical image VQA

|Paper|PDF|Code|
|---|---|---|
|Masked vision and language pre-training with unimodal and multimodal contrastive losses for medical visual question answering|[PDF]()|[Code]()|
|Med-Flamingo: a Multimodal Medical Few-shot Learner|[PDF]()|[Code]()|
|RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training|[PDF]()|[Code]()|
|Multi-modal Adapter for Medical Vision-and-Language Learning|[PDF]()|[Code]()|
|Parameter-Efficient Transfer Learning for Medical Visual Question Answering|[PDF]()|[Code]()|
|Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering|[PDF]()|[Code]()|
|Vision-Language Transformer for Interpretable Pathology Visual Question Answering|[PDF]()|[Code]()|
|Surgical-vqa: Visual question answering in surgical scenes using transformer|[PDF]()|[Code]()|
|LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation|[PDF]()|[Code]()|
|LLM-Assisted Multi-Teacher Continual Learning for Surgical Visual Question Answering|[PDF]()|[Code]()|
|MedBLIP: Bootstrapping Language-Image Pre-training from 3D Medical Images and Texts|[PDF]()|[Code]()|
|Open-ended medical visual question answering through prefix tuning of language models|[PDF]()|[Code]()|
|Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering|[PDF]()|[Code]()|
|An Effective Pre-trained Visual Encoder for Medical Visual Question Answering|[PDF]()|[Code]()|
|Interpretable medical image visual question answering via multi-modal relationship graph learning|[PDF]()|[Code]()|
|Medical knowledge-based network for Patient-oriented Visual Question Answering|[PDF]()|[Code]()|

## KD in Medical image detection

|Paper|PDF|Code|
|---|---|---|
|Weakly supervised one-stage vision and language disease detection using large scale pneumonia and pneumothorax studies|[PDF]()|[Code]()|
|Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models|[PDF]()|[Code]()|
|Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models|[PDF]()|[Code]()|
|Zero-Shot Nuclei Detection via Visual-Language Pre-trained Models|[PDF]()|[Code]()|
|Medical image understanding with pretrained vision language models: A comprehensive study|[PDF]()|[Code]()|
|MediCLIP: Adapting CLIP for Few-shot Medical Image Anomaly Detection|[PDF]()|[Code]()|
|CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios|[PDF]()|[Code]()|

## KD in Medical image generation

|Paper|PDF|Code|
|---|---|---|
|Medical image synthesis via fine-grained image-text alignment and anatomy-pathology prompting|[PDF]()|[Code]()|
|Medsyn: Text-guided anatomy-aware synthesis of high-fidelity 3d ct images|[PDF]()|[Code]()|
|Diffusion-based data augmentation for skin disease classification: Impact across original medical datasets to fully synthetic images|[PDF]()|[Code]()|
|Vision-Language Generative Model for View-Specific Chest X-ray Generation|[PDF]()|[Code]()|
|Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation|[PDF]()|[Code]()|
|Adapting Pretrained Vision-Language Foundational Models to Medical Imaging Domains|[PDF]()|[Code]()|
|A vision–language foundation model for the generation of realistic chest X-ray images|[PDF]()|[Code]()|
|MedM2G:Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant|[PDF]()|[Code]()|
|Controllable text-to-image synthesis for multi-modality MR images|[PDF]()|[Code]()|
|Surgical Text-to-Image Generation|[PDF]()|[Code]()|

## KD in Medical image large model

|Paper|PDF|Code|
|---|---|---|
|PRIOR: Prototype Representation Joint Learning from Medical Images and Reports|[PDF]()|[Code]()|
|Enhancing medical vision-language contrastive learning via inter-matching relation modelling|[PDF]()|[Code]()|
|Multi-task paired masking with alignment modeling for medical vision-language pre-training|[PDF]()|[Code]()|
|MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning|[PDF]()|[Code]()|
|Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning|[PDF]()|[Code]()|
|DeViDe: Faceted medical knowledge for improved medical vision-language pre-training|[PDF]()|[Code]()|
|Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining|[PDF]()|[Code]()|
|MM-Retinal: Knowledge-Enhanced Foundational Pretraining with Fundus Image-Text Expertise|[PDF]()|[Code]()|
|DeViDe: Faceted medical knowledge for improved medical vision-language pre-training|[PDF]()|[Code]()|
|MM-Retinal: Knowledge-Enhanced Foundational Pretraining with Fundus Image-Text Expertise|[PDF]()|[Code]()|
|Towards Medical Vision-Language Contrastive Pre-training via Study-Oriented Semantic Exploration|[PDF]()|[Code]()|
|MITER: Medical Image–TExt joint adaptive pretRaining with multi-level contrastive learning|[PDF]()|[Code]()|
|Continual self-supervised learning: Towards universal multi-modal medical data representation learning|[PDF]()|[Code]()|
|UniDCP: Unifying Multiple Medical Vision-language Tasks via Dynamic Cross-modal Learnable Prompts|[PDF]()|[Code]()|
|MedCLIP: Contrastive Learning from Unpaired Medical Images and Text|[PDF]()|[Code]()|
|Improving Medical Vision-Language Contrastive Pretraining With Semantics-Aware Triage|[PDF]()|[Code]()|
|Lvm-med: Learning large-scale self-supervised vision models for medical imaging via second-order graph matching|[PDF]()|[Code]()|
|Unified Medical Image Pre-training in Language-Guided Common Semantic Space|[PDF]()|[Code]()|
|M3D: Advancing 3D Medical Image Analysis with Multi-Modal Large Language Models|[PDF]()|[Code]()|
|Merlin: A Vision Language Foundation Model for 3D Computed Tomography|[PDF]()|[Code]()|









