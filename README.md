# VLM-in-MIA

## VLM in Medical image diagnosis and classification
|Paper|PDF|Code|
|---|---|---|
|ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.html)|-|
|BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_69)|[Code](https://github.com/monajati/BERTHop)|
|TandemNet: Distilling Knowledge from Medical Images Using Diagnostic Reports as Optional Semantic References|[PDF](https://link.springer.com/chapter/10.1007/978-3-319-66179-7_37)|-|
|Pay attention to doctor–patient dialogues: Multi-modal knowledge graph attention image-text embedding for COVID-19 diagnosis|[PDF](https://www.sciencedirect.com/science/article/pii/S1566253521001159)|-|
|Text-Guided Foundation Model Adaptation for Pathological Image Classification|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_27)|[Code](https://github.com/Yunkun-Zhang/CITE)|
|Report-Concept Textual-Prompt Learning for Enhancing X-ray Diagnosis|[PDF](https://dl.acm.org/doi/abs/10.1145/3664647.3681568)|-|
|A diagnostic report supervised deep learning model training strategy for diagnosis of COVID-19|[PDF](https://www.sciencedirect.com/science/article/pii/S0031320323009299)|-|
|Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-47401-9_22)|-|
|Nodule-CLIP: Lung nodule classification based on multi-modal contrastive learning|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S0010482524005894)|-|
|Contrastive Cross-Modal Pre-Training: A General Strategy for Small Sample Medical Imaging|[PDF](https://ieeexplore.ieee.org/abstract/document/9531406/)|-|
|FlexR: Few-shot Classification with Language Embeddings for Structured Reporting of Chest X-rays|[PDF](https://proceedings.mlr.press/v227/keicher24a.html)|-|
|The Rise of AI Language Pathologists: Exploring Two-level Prompt Learning for Few-shot Weakly-supervised Whole Slide Image Classification|[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d599b81036fd1a3b3949b7d444f31082-Abstract-Conference.html)|[Code](https://github.com/miccaiif/TOP)|
|Exploring low-resource medical image classification with weakly supervised prompt learning|[PDF](https://www.sciencedirect.com/science/article/pii/S0031320324000013)|-|
|Self-supervised multi-modal training from uncurated images and reports enables monitoring AI in radiology|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S1361841523002815)|-|
|CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Lai_CARZero_Cross-Attention_Alignment_for_Radiology_Zero-Shot_Classification_CVPR_2024_paper.html)|[Code](https://github.com/laihaoran/CARZero)|
|Multi-Label Generalized Zero Shot Chest Xray Classification By Combining Image-Text Information With Feature Disentanglement|[PDF](https://ieeexplore.ieee.org/abstract/document/10601163/)|-|
|TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-rays|[PDF](http://openaccess.thecvf.com/content_cvpr_2018/html/Wang_TieNet_Text-Image_Embedding_CVPR_2018_paper.html)|-|
|Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Pre-training Framework|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Phan_Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_CVPR_2024_paper.html)|[Code](https://github.com/HieuPhan33/MAVL)|
|Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images|[PDF](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Visual_Language_Pretrained_Multiple_Instance_Zero-Shot_Transfer_for_Histopathology_Images_CVPR_2023_paper.html)|[Code](https://github.com/mahmoodlab/MI-Zero)|
|CLIPath: Fine-tune CLIP with Visual Feature Fusion for Pathology Image Analysis Towards Minimizing Data Collection Efforts|[PDF](https://openaccess.thecvf.com/content/ICCV2023W/CVAMD/html/Lai_CLIPath_Fine-Tune_CLIP_with_Visual_Feature_Fusion_for_Pathology_Image_ICCVW_2023_paper.html)|-|


## VLM in Medical image segmentation

|Paper|PDF|Code|
|---|---|---|
|Ariadne’s Thread: Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray Images|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43901-8_69)|[Code](https://github.com/Junelin2333/LanGuideMedSeg-MICCAI2023)|
|Text-guided cross-position attention for segmentation: Case of medical image|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_52)|-|
|ConTEXTual net: a multimodal vision-language model for segmentation of pneumothorax|[PDF](https://link.springer.com/article/10.1007/s10278-024-01051-8)|[Code](https://github.com/zhuemann/ConTEXTualSegmentation)|
|TPRO: Text-Prompting-Based weakly supervised histopathology tissue segmentation|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43907-0_11)|[Code](https://github.com/zhangst431/TPRO)|
|Text promptable surgical instrument segmentation with vision-language models|[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/hash/5af741d487c5f0b08bfe56e11d1883e4-Abstract-Conference.html)|[Code](https://github.com/franciszzj/TP-SIS)|
|Bi-VLGM: Bi-Level Class-Severity-Aware Vision-Language Graph Matching for Text Guided Medical Image Segmentation|[PDF](https://arxiv.org/abs/2305.12231)|-|
|Cross-Modal Conditioned Reconstruction for Language-guided Medical Image Segmentation|[PDF](https://arxiv.org/abs/2404.02845)|[Code](https://github.com/ShashankHuang/RecLMIS)|
|VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72114-4_68)|[Code](https://github.com/naamiinepal/vlsm-adapter)|
|CAT: Coordinating Anatomical-Textual Prompts for Multi-Organ and Tumor Segmentation|[PDF](https://arxiv.org/abs/2406.07085)|[Code](https://github.com/zongzi3zz/CAT)|
|Universal and extensible language-vision models for organ segmentation and tumor detection from abdominal computed tomography|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S1361841524001518)|[Code](https://github.com/ljwztc/CLIP-Driven-Universal-Model)|
|Clip-driven universal model for organ segmentation and tumor detection|[PDF](http://openaccess.thecvf.com/content/ICCV2023/html/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.html)|[Code](https://github.com/ljwztc/CLIP-Driven-Universal-Model)|
|FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation|[PDF](https://arxiv.org/abs/2403.08059)|[Code](https://github.com/arcadelab/fluorosam)|
|Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation|[PDF](https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Aleem_Test-Time_Adaptation_with_SaLIP_A_Cascade_of_SAM_and_CLIP_CVPRW_2024_paper.html)|[Code](https://github.com/aleemsidra/SaLIP)|
|Zept: Zero-shot pan-tumor segmentation via query-disentangling and self-prompting|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_ZePT_Zero-Shot_Pan-Tumor_Segmentation_via_Query-Disentangling_and_Self-Prompting_CVPR_2024_paper.html)|[Code](https://github.com/Yankai96/ZePT)|
|PFPs: Prompt-guided Flexible Pathological Segmentation for Diverse Potential Outcomes Using Large Vision and Language Models|[PDF](https://arxiv.org/abs/2407.09979)|-|
|MedCLIP-SAM: Bridging text and image towards universal medical image segmentation|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72390-2_60)|[Code](https://github.com/HealthX-Lab/MedCLIP-SAM)|
|Lvit: language meets vision transformer in medical image segmentation|[PDF](https://ieeexplore.ieee.org/abstract/document/10172039/)|[Code](https://github.com/HUANGLIZI/LViT)|
|Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports|[PDF](https://arxiv.org/abs/2405.14230)|-|
|SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging|[PDF](https://arxiv.org/abs/2403.16578)|-|
|Generative text-guided 3d vision-language pretraining for unified medical image segmentation|[PDF](https://arxiv.org/abs/2306.04811)|-|
|T3d: Towards 3d medical image understanding through vision-language pre-training|[PDF](https://arxiv.org/abs/2312.01529)|-|
|One model to rule them all: Towards universal segmentation for medical images with text prompts|[PDF](https://arxiv.org/abs/2312.17183)|[Code](https://github.com/zhaoziheng/SAT)|
|Med3DInsight: Enhancing 3D Medical Image Understanding with 2D Multi-Modal Large Language Models|[PDF](https://arxiv.org/abs/2403.05141)|[Code](https://github.com/Qybc/Med3DInsight)|


## VLM in Medical image report generation

|Paper|PDF|Code|
|---|---|---|
|AERMNet: Attention-enhanced relational memory network for medical image report generation|[PDF](https://www.sciencedirect.com/science/article/abs/pii/S0169260723006454)|[Code](https://github.com/llttxx/AERMNET)|
|Kdtnet: medical image report generation via knowledge-driven transformer|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-00129-1_8)|-|
|RepsNet: Combining Vision with Language for Automated Medical Reports|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_68)|[Code](https://sites.google.com/view/repsnet)|
|Radiology Report Generation via Visual Recalibration and Context Gating-Aware|[PDF](https://link.springer.com/chapter/10.1007/978-981-99-7074-2_9)|[Code](https://github.com/Eleanorhxd/VRCG)|
|Visual-Textual Attentive Semantic Consistency for Medical Report Generation|[PDF](http://openaccess.thecvf.com/content/ICCV2021/html/Zhou_Visual-Textual_Attentive_Semantic_Consistency_for_Medical_Report_Generation_ICCV_2021_paper.html)|-|
|CGFTrans: Cross-Modal Global Feature Fusion Transformer for Medical Report Generation|[PDF](https://ieeexplore.ieee.org/abstract/document/10557585/)|[Code](https://github.com/LimingXuM3/CGFTrans)|
|CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs|[PDF](https://openaccess.thecvf.com/content/WACV2024/html/Shentu_CXR-IRGen_An_Integrated_Vision_and_Language_Model_for_the_Generation_WACV_2024_paper.html)|[Code](https://github.com/junjie-shentu/CXR-IRGen)|
|Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting|[PDF](https://ieeexplore.ieee.org/abstract/document/10552817)|[Code](https://github.com/yangyan22/Token-Mixer)|
|PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation|[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/28038)|-|
|A label information fused medical image report generation framework|[PDF](https://www.sciencedirect.com/science/article/pii/S0933365724000654)|[Code](https://github.com/watersunhznu/LIFMRG)|
|Clinical-BERT: Vision-Language Pre-training for Radiograph Diagnosis and Reports Generation|[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/20204)|[Code](https://github.com/fxsjy/jieba)|
|Dia-LLaMA: Towards Large Language Model-driven CT Report Generation|[PDF](https://arxiv.org/abs/2403.16386)|-|
|TRRG: Towards Truthful Radiology Report Generation With Cross-modal Disease Clue Enhanced Large Language Model|[PDF](https://arxiv.org/abs/2408.12141)|-|
|An Organ-aware Diagnosis Framework for Radiology Report Generation|[PDF](https://ieeexplore.ieee.org/abstract/document/10579857/)|-|
|MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation|[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/25100)|-|
|Non-local Attention Improves Description Generation for Retinal Images|[PDF](https://openaccess.thecvf.com/content/WACV2022/html/Huang_Non-Local_Attention_Improves_Description_Generation_for_Retinal_Images_WACV_2022_paper.html)|[Code](https://github.com/Jhhuangkay/Non-local-Attention-Improves-Description-Generation-for-Retinal-Images)|
|Enhancing the vision–language foundation model with key semantic knowledge-emphasized report refinement|[PDF](https://arxiv.org/abs/2401.11421)|-|
|Vision-language model for generating textual descriptions from clinical images: model development and validation study|[PDF](https://formative.jmir.org/2024/1/e32690)|-|
|IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training|[PDF](https://ieeexplore.ieee.org/abstract/document/10646593/)|-|
|METransformer: Radiology Report Generation by Transformer with Multiple Learnable Expert Tokens|[PDF](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_METransformer_Radiology_Report_Generation_by_Transformer_With_Multiple_Learnable_Expert_CVPR_2023_paper.html)|-|
|Prior Guided Transformer for Accurate Radiology Reports Generation|[PDF](https://ieeexplore.ieee.org/abstract/document/9852309/)|-|
|Multimodal image-text matching improves retrieval-based chest x-ray report generation|[PDF](https://proceedings.mlr.press/v227/jeong24a.html)|[Code](https://github.com/rajpurkarlab/X-REM)|
|PhraseAug: An Augmented Medical Report Generation Model with Phrasebook|[PDF](https://ieeexplore.ieee.org/abstract/document/10560051/)|-|
|Fine-grained image-text alignment in medical imaging enables cyclic image-report generation|[PDF](https://arxiv.org/abs/2312.08078)|-|
|FgKF: Fine-Grained Knowledge Fusion for Radiology Report Generation|[PDF](https://link.springer.com/chapter/10.1007/978-981-99-9864-7_16)|-|
|Multi-Grained Radiology Report Generation With Sentence-Level Image-Language Contrastive Learning|[PDF](https://ieeexplore.ieee.org/abstract/document/10458706/)|-|
|AlignTransformer: Hierarchical Alignment of Visual Regions and Disease Tags for Medical Report Generation|[PDF](https://link.springer.com/chapter/10.1007/978-3-030-87199-4_7)|-|
|Improving radiology report generation with multi-grained abnormality prediction|[PDF](https://www.sciencedirect.com/science/article/pii/S0925231224008932)|-|
|Self adaptive global-local feature enhancement for radiology report generation|[PDF](https://ieeexplore.ieee.org/abstract/document/10222405/)|-|
|Interactive and Explainable Region-guided Radiology Report Generation|[PDF](http://openaccess.thecvf.com/content/CVPR2023/html/Tanida_Interactive_and_Explainable_Region-Guided_Radiology_Report_Generation_CVPR_2023_paper.html)|[Code](https://github.com/ttanida/rgrg)|
|Complex Organ Mask Guided Radiology Report Generation|[PDF](https://openaccess.thecvf.com/content/WACV2024/html/Gu_Complex_Organ_Mask_Guided_Radiology_Report_Generation_WACV_2024_paper.html)|[Code](https://github.com/GaryGuTC/COMG_model)|
|Attribute Prototype-guided Iterative Scene Graph for Explainable Radiology Report Generation|[PDF](https://ieeexplore.ieee.org/abstract/document/10587279/)|[Code](https://github.com/giantke/AP-ISG)|
|Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Bu_Instance-level_Expert_Knowledge_and_Aggregate_Discriminative_Attention_for_Radiology_Report_CVPR_2024_paper.html)|[Code](https://github.com/hnjzbss/EKAGen)|


## VLM in Medical image VQA

|Paper|PDF|Code|
|---|---|---|
|Masked vision and language pre-training with unimodal and multimodal contrastive losses for medical visual question answering|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43907-0_36)|[Code](https://github.com/pengfeiliHEU/MUMC)|
|Med-Flamingo: a Multimodal Medical Few-shot Learner|[PDF](https://proceedings.mlr.press/v225/moor23a.html)|[Code](https://github.com/snap-stanford/med-flamingo)|
|RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training|[PDF](https://dl.acm.org/doi/abs/10.1145/3581783.3611830)|[Code](https://github.com/GanjinZero/RAMM)|
|Multi-modal Adapter for Medical Vision-and-Language Learning|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-45673-2_39)|-|
|Parameter-Efficient Transfer Learning for Medical Visual Question Answering|[PDF](https://ieeexplore.ieee.org/abstract/document/10256025/)|-|
|Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering|[PDF](https://arxiv.org/abs/2404.16192)|-|
|Vision-Language Transformer for Interpretable Pathology Visual Question Answering|[PDF](https://ieeexplore.ieee.org/abstract/document/9745795/)|-|
|Surgical-vqa: Visual question answering in surgical scenes using transformer|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-16449-1_4)|[Code](https://github.com/lalithjets/Surgical_VQA.git)|
|LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation|[PDF](https://arxiv.org/abs/2305.11490)|[Code](https://github.com/hyn2028/llm-cxr)|
|LLM-Assisted Multi-Teacher Continual Learning for Surgical Visual Question Answering|[PDF](https://arxiv.org/abs/2402.16664)|[Code](https://github.com/yuyangdu01/LLM-CL-VQA)|
|MedBLIP: Bootstrapping Language-Image Pre-training from 3D Medical Images and Texts|[PDF](https://arxiv.org/abs/2305.10799)|[Code](https://github.com/Qybc/MedBLIP)|
|Open-ended medical visual question answering through prefix tuning of language models|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_70)|[Code](https://github.com/tjvsonsbeek/open-ended-medical-vqa)|
|Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering|[PDF](https://arxiv.org/abs/2404.16192)|-|
|An Effective Pre-trained Visual Encoder for Medical Visual Question Answering|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-46677-9_32)|-|
|Interpretable medical image visual question answering via multi-modal relationship graph learning|[PDF](https://www.sciencedirect.com/science/article/pii/S1361841524002044)|[Code](https://github.com/Holipori/Medical-CXR-VQA)|
|Medical knowledge-based network for Patient-oriented Visual Question Answering|[PDF](https://www.sciencedirect.com/science/article/pii/S0306457322003429)|[Code](https://github.com/cs-jerhuang/P-VQA)|

## VLM in Medical image detection

|Paper|PDF|Code|
|---|---|---|
|Weakly supervised one-stage vision and language disease detection using large scale pneumonia and pneumothorax studies|[PDF](https://link.springer.com/chapter/10.1007/978-3-030-59719-1_5)|[Code](https://github.com/leotam/MIMIC-CXR-annotations)|
|Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models|[PDF](https://arxiv.org/abs/2404.12920)|-|
|Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43904-9_28)|[Code](https://github.com/vios-s)|
|Zero-Shot Nuclei Detection via Visual-Language Pre-trained Models|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-43987-2_67)|[Code](https://github.com/wuyongjianCODE/VLPMNuD)|
|Medical image understanding with pretrained vision language models: A comprehensive study|[PDF](https://arxiv.org/abs/2209.15517)|[Code](https://github.com/MembrLab/MIU-VL)|
|MediCLIP: Adapting CLIP for Few-shot Medical Image Anomaly Detection|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72120-5_43)|[Code](https://github.com/cnulab/MediCLIP)|
|CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios|[PDF](https://arxiv.org/abs/2404.15272)|-|

## VLM in Medical image generation

|Paper|PDF|Code|
|---|---|---|
|Medical image synthesis via fine-grained image-text alignment and anatomy-pathology prompting|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72390-2_23)|-|
|Medsyn: Text-guided anatomy-aware synthesis of high-fidelity 3d ct images|[PDF](https://ieeexplore.ieee.org/abstract/document/10566053/)|[Code](https://github.com/batmanlab/MedSyn)|
|Diffusion-based data augmentation for skin disease classification: Impact across original medical datasets to fully synthetic images|[PDF](https://ieeexplore.ieee.org/abstract/document/10566053/)|[Code](https://github.com/batmanlab/MedSyn)|
|Vision-Language Generative Model for View-Specific Chest X-ray Generation|[PDF](https://proceedings.mlr.press/v248/lee24a.html)|[Code](https://github.com/ttumyche/UniXGen)|
|Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation|[PDF](https://ieeexplore.ieee.org/abstract/document/10635417/)|-|
|Adapting Pretrained Vision-Language Foundational Models to Medical Imaging Domains|[PDF](https://arxiv.org/abs/2210.04133)|-|
|A vision–language foundation model for the generation of realistic chest X-ray images|[PDF](https://www.nature.com/articles/s41551-024-01246-y)|[Code](https://stanfordmlgroup.github.io/competitions/chexpert/)|
|MedM2G:Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Zhan_MedM2G_Unifying_Medical_Multi-Modal_Generation_via_Cross-Guided_Diffusion_with_Visual_CVPR_2024_paper.html)|-|
|Controllable text-to-image synthesis for multi-modality MR images|[PDF](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Controllable_Text-to-Image_Synthesis_for_Multi-Modality_MR_Images_WACV_2024_paper.html)|-|
|Surgical Text-to-Image Generation|[PDF](https://arxiv.org/abs/2407.09230)|[Code](https://camma-public.github.io/endogen/)|

## VLM in Medical image large model

|Paper|PDF|Code|
|---|---|---|
|PRIOR: Prototype Representation Joint Learning from Medical Images and Reports|[PDF](http://openaccess.thecvf.com/content/ICCV2023/html/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.html)|[Code](https://github.com/QtacierP/PRIOR)|
|Enhancing medical vision-language contrastive learning via inter-matching relation modelling|[PDF](https://arxiv.org/abs/2401.10501)|-|
|Multi-task paired masking with alignment modeling for medical vision-language pre-training|[PDF](https://ieeexplore.ieee.org/abstract/document/10288259/)|-|
|MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Li_MLIP_Enhancing_Medical_Visual_Representation_with_Divergence_Encoder_and_Knowledge-guided_CVPR_2024_paper.html)|[Code](https://github.com/gentlefress/MLIP)|
|Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning|[PDF](https://proceedings.neurips.cc/paper_files/paper/2022/hash/d925bda407ada0df3190df323a212661-Abstract-Conference.html)|[Code](https://github.com/HKU-MedAI/MGCA)|
|DeViDe: Faceted medical knowledge for improved medical vision-language pre-training|[PDF](https://arxiv.org/abs/2404.03618)|-|
|Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining|[PDF](https://arxiv.org/abs/2304.14204)|[Code](https://github.com/chenzcv7/MOTOR)|
|MM-Retinal: Knowledge-Enhanced Foundational Pretraining with Fundus Image-Text Expertise|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-72378-0_67)|[Code](https://github.com/lxirich/MM-Retinal)|
|MITER: Medical Image–TExt joint adaptive pretRaining with multi-level contrastive learning|[PDF](https://www.sciencedirect.com/science/article/pii/S0957417423020286)|[Code](https://github.com/ZhuYi98/MITER)|
|Continual self-supervised learning: Towards universal multi-modal medical data representation learning|[PDF](https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Continual_Self-supervised_Learning_Towards_Universal_Multi-modal_Medical_Data_Representation_Learning_CVPR_2024_paper.html)|[Code](https://github.com/yeerwen/MedCoSS)|
|UniDCP: Unifying Multiple Medical Vision-language Tasks via Dynamic Cross-modal Learnable Prompts|[PDF](https://ieeexplore.ieee.org/abstract/document/10526408/)|-|
|MedCLIP: Contrastive Learning from Unpaired Medical Images and Text|[PDF](https://arxiv.org/abs/2210.10163)|[Code](https://github.com/RyanWangZf/MedCLIP)|
|Improving Medical Vision-Language Contrastive Pretraining With Semantics-Aware Triage|[PDF](https://ieeexplore.ieee.org/abstract/document/10182304/)|[Code](https://github.com/liubo105/SAT)|
|Lvm-med: Learning large-scale self-supervised vision models for medical imaging via second-order graph matching|[PDF](https://proceedings.neurips.cc/paper_files/paper/2023/hash/58cc11cda2a2679e8af5c6317aed0af8-Abstract-Conference.html)|[Code](https://github.com/duyhominhnguyen/LVM-Med)|
|Unified Medical Image Pre-training in Language-Guided Common Semantic Space|[PDF](https://link.springer.com/chapter/10.1007/978-3-031-73004-7_8)|-|
|M3D: Advancing 3D Medical Image Analysis with Multi-Modal Large Language Models|[PDF](https://arxiv.org/abs/2404.00578)|[Code](https://github.com/BAAI-DCAI/M3D)|
|Merlin: A Vision Language Foundation Model for 3D Computed Tomography|[PDF](https://arxiv.org/abs/2406.06512)|-|









